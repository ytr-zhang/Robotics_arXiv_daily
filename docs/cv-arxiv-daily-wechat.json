{"Manipulation": {"2601.23087": "- 2026-01-30, **Temporally Coherent Imitation Learning via Latent Action Flow Matching for Robotic Manipulation**, Liu Hong Team, Paper: [http://arxiv.org/abs/2601.23087](http://arxiv.org/abs/2601.23087)\n", "2601.22988": "- 2026-01-30, **Learning Geometrically-Grounded 3D Visual Representations for View-Generalizable Robotic Manipulation**, Guang Chen Team, Paper: [http://arxiv.org/abs/2601.22988](http://arxiv.org/abs/2601.22988)\n", "2601.22965": "- 2026-01-30, **Self-Imitated Diffusion Policy for Efficient and Robust Visual Navigation**, Wuyue Zhao Team, Paper: [http://arxiv.org/abs/2601.22965](http://arxiv.org/abs/2601.22965)\n", "2601.22356": "- 2026-01-29, **PoSafeNet: Safe Learning with Poset-Structured Neural Nets**, Daniela Rus Team, Paper: [http://arxiv.org/abs/2601.22356](http://arxiv.org/abs/2601.22356)\n", "2601.22242": "- 2026-01-29, **Aligning Microscopic Vehicle and Macroscopic Traffic Statistics: Reconstructing Driving Behavior from Partial Data**, Bowen Weng Team, Paper: [http://arxiv.org/abs/2601.22242](http://arxiv.org/abs/2601.22242)\n", "2601.22074": "- 2026-01-29, **mjlab: A Lightweight Framework for GPU-Accelerated Robot Learning**, Pieter Abbeel Team, Paper: [http://arxiv.org/abs/2601.22074](http://arxiv.org/abs/2601.22074), Code: **[https://github.com/mujocolab/mjlab](https://github.com/mujocolab/mjlab)**\n", "2601.22206": "- 2026-01-29, **Causal Imitation Learning Under Measurement Error and Distribution Shift**, AmirEmad Ghassami Team, Paper: [http://arxiv.org/abs/2601.22206](http://arxiv.org/abs/2601.22206)\n", "2601.22018": "- 2026-01-30, **PocketDP3: Efficient Pocket-Scale 3D Visuomotor Policy**, Jie Mei Team, Paper: [http://arxiv.org/abs/2601.22018](http://arxiv.org/abs/2601.22018)\n", "2601.21998": "- 2026-01-29, **Causal World Modeling for Robot Control**, Yinghao Xu Team, Paper: [http://arxiv.org/abs/2601.21998](http://arxiv.org/abs/2601.21998), Code: **[https://technology.robbyant.com/lingbot-va](https://technology.robbyant.com/lingbot-va)**\n", "2601.21971": "- 2026-01-29, **MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts**, Stefanie Speidel Team, Paper: [http://arxiv.org/abs/2601.21971](http://arxiv.org/abs/2601.21971)\n", "2601.21926": "- 2026-01-29, **Information Filtering via Variational Regularization for Robot Manipulation**, Jie Me Team, Paper: [http://arxiv.org/abs/2601.21926](http://arxiv.org/abs/2601.21926)\n", "2601.21718": "- 2026-01-29, **When does predictive inverse dynamics outperform behavior cloning?**, Sergio Valcarcel Macua Team, Paper: [http://arxiv.org/abs/2601.21718](http://arxiv.org/abs/2601.21718)\n", "2601.21416": "- 2026-01-29, **Spotlighting Task-Relevant Features: Object-Centric Representations for Better Generalization in Robotic Manipulation**, Liming Chen Team, Paper: [http://arxiv.org/abs/2601.21416](http://arxiv.org/abs/2601.21416)\n", "2601.21394": "- 2026-01-29, **Towards Space-Based Environmentally-Adaptive Grasping**, Aleksandr Artemov Team, Paper: [http://arxiv.org/abs/2601.21394](http://arxiv.org/abs/2601.21394)\n", "2601.21251": "- 2026-01-29, **Abstracting Robot Manipulation Skills via Mixture-of-Experts Diffusion Policies**, Harold Soh Team, Paper: [http://arxiv.org/abs/2601.21251](http://arxiv.org/abs/2601.21251)\n", "2601.20776": "- 2026-01-28, **Learning From a Steady Hand: A Weakly Supervised Agent for Robot Assistance under Microscopy**, Christos Bergeles Team, Paper: [http://arxiv.org/abs/2601.20776](http://arxiv.org/abs/2601.20776)\n", "2601.20555": "- 2026-01-28, **Vibro-Sense: Robust Vibration-based Impulse Response Localization and Trajectory Tracking for Robotic Hands**, Nicol\u00e1s Navarro-Guerrero Team, Paper: [http://arxiv.org/abs/2601.20555](http://arxiv.org/abs/2601.20555)\n", "2601.20540": "- 2026-01-28, **Advancing Open-source World Models**, Hao Ouyang Team, Paper: [http://arxiv.org/abs/2601.20540](http://arxiv.org/abs/2601.20540), Code: **[https://technology.robbyant.com/lingbot-world](https://technology.robbyant.com/lingbot-world)**\n", "2601.20381": "- 2026-01-28, **STORM: Slot-based Task-aware Object-centric Representation for robotic Manipulation**, Liming Chen Team, Paper: [http://arxiv.org/abs/2601.20381](http://arxiv.org/abs/2601.20381)\n", "2601.20334": "- 2026-01-28, **Demonstration-Free Robotic Control via LLM Agents**, Tiffany J. Hwu Team, Paper: [http://arxiv.org/abs/2601.20334](http://arxiv.org/abs/2601.20334)\n", "2602.02473": "- 2026-02-02, **HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos**, Ping Tan Team, Paper: [http://arxiv.org/abs/2602.02473](http://arxiv.org/abs/2602.02473)\n", "2602.02459": "- 2026-02-02, **TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments**, Jiaqi Ma Team, Paper: [http://arxiv.org/abs/2602.02459](http://arxiv.org/abs/2602.02459)\n", "2602.02454": "- 2026-02-02, **World-Gymnast: Training Robots with Reinforcement Learning in a World Model**, Sherry Yang Team, Paper: [http://arxiv.org/abs/2602.02454](http://arxiv.org/abs/2602.02454), Code: **[https://world-gymnast.github.io/](https://world-gymnast.github.io/)**\n", "2602.02405": "- 2026-02-02, **Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning**, Alan Ritter Team, Paper: [http://arxiv.org/abs/2602.02405](http://arxiv.org/abs/2602.02405)\n", "2602.02402": "- 2026-02-02, **SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation**, Jiangmiao Pang Team, Paper: [http://arxiv.org/abs/2602.02402](http://arxiv.org/abs/2602.02402), Code: **[https://city-super.github.io/SoMA/](https://city-super.github.io/SoMA/)**\n", "2602.02396": "- 2026-02-02, **PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning**, Alexander Schperberg Team, Paper: [http://arxiv.org/abs/2602.02396](http://arxiv.org/abs/2602.02396)\n", "2602.01939": "- 2026-02-02, **Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy**, Qiang Nie Team, Paper: [http://arxiv.org/abs/2602.01939](http://arxiv.org/abs/2602.01939)\n", "2602.01916": "- 2026-02-02, **ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning**, Sifa Zheng Team, Paper: [http://arxiv.org/abs/2602.01916](http://arxiv.org/abs/2602.01916)\n", "2602.01870": "- 2026-02-02, **BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models**, Matteo Matteucci Team, Paper: [http://arxiv.org/abs/2602.01870](http://arxiv.org/abs/2602.01870)\n", "2602.01789": "- 2026-02-03, **RFS: Reinforcement learning with Residual flow steering for dexterous manipulation**, Abhishek Gupta Team, Paper: [http://arxiv.org/abs/2602.01789](http://arxiv.org/abs/2602.01789)\n", "2602.01662": "- 2026-02-02, **AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act**, Yu She Team, Paper: [http://arxiv.org/abs/2602.01662](http://arxiv.org/abs/2602.01662)\n", "2602.01632": "- 2026-02-02, **A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation**, Shreyas Kousik Team, Paper: [http://arxiv.org/abs/2602.01632](http://arxiv.org/abs/2602.01632), Code: **[https://sew-mimic.com/](https://sew-mimic.com/)**\n", "2602.01357": "- 2026-02-01, **Your Self-Play Algorithm is Secretly an Adversarial Imitator: Understanding LLM Self-Play through the Lens of Imitation Learning**, Weitong Zhang Team, Paper: [http://arxiv.org/abs/2602.01357](http://arxiv.org/abs/2602.01357)\n", "2602.01166": "- 2026-02-01, **Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models**, Shanghang Zhang Team, Paper: [http://arxiv.org/abs/2602.01166](http://arxiv.org/abs/2602.01166)\n", "2602.01158": "- 2026-02-01, **Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs**, Matteo Matteucci Team, Paper: [http://arxiv.org/abs/2602.01158](http://arxiv.org/abs/2602.01158)\n", "2602.01153": "- 2026-02-01, **UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors**, Shan Luo Team, Paper: [http://arxiv.org/abs/2602.01153](http://arxiv.org/abs/2602.01153)\n", "2602.01115": "- 2026-02-01, **KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV**, Ziyang Wang Team, Paper: [http://arxiv.org/abs/2602.01115](http://arxiv.org/abs/2602.01115)\n", "2602.01100": "- 2026-02-01, **StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating**, Lu Fang Team, Paper: [http://arxiv.org/abs/2602.01100](http://arxiv.org/abs/2602.01100)\n", "2602.01085": "- 2026-02-01, **Estimating Force Interactions of Deformable Linear Objects from their Shapes**, Quang-Cuong Pham Team, Paper: [http://arxiv.org/abs/2602.01085](http://arxiv.org/abs/2602.01085)\n", "2602.01067": "- 2026-02-01, **A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation**, Jose Barreiros Team, Paper: [http://arxiv.org/abs/2602.01067](http://arxiv.org/abs/2602.01067)\n", "2602.03668": "- 2026-02-03, **MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction**, Jungwoo Lee Team, Paper: [http://arxiv.org/abs/2602.03668](http://arxiv.org/abs/2602.03668)\n", "2602.03188": "- 2026-02-03, **Hierarchical Proportion Models for Motion Generation via Integration of Motion Primitives**, Sho Sakaino Team, Paper: [http://arxiv.org/abs/2602.03188](http://arxiv.org/abs/2602.03188)\n", "2602.02839": "- 2026-02-02, **Language Movement Primitives: Grounding Language Models in Robot Motion**, Simon Stepputtis Team, Paper: [http://arxiv.org/abs/2602.02839](http://arxiv.org/abs/2602.02839)\n", "2602.02762": "- 2026-02-02, **On the Sample Efficiency of Inverse Dynamics Models for Semi-Supervised Imitation Learning**, S\u00e9bastien Lachapelle Team, Paper: [http://arxiv.org/abs/2602.02762](http://arxiv.org/abs/2602.02762)\n", "2602.04877": "- 2026-02-04, **CoWTracker: Tracking by Warping instead of Correlation**, Andrea Vedaldi Team, Paper: [http://arxiv.org/abs/2602.04877](http://arxiv.org/abs/2602.04877)\n", "2602.04522": "- 2026-02-04, **A Unified Complementarity-based Approach for Rigid-Body Manipulation and Motion Prediction**, Riddhiman Laha Team, Paper: [http://arxiv.org/abs/2602.04522](http://arxiv.org/abs/2602.04522)\n", "2602.04243": "- 2026-02-04, **Viewpoint Matters: Dynamically Optimizing Viewpoints with Masked Autoencoder for Visual Manipulation**, Wenzhao Lian Team, Paper: [http://arxiv.org/abs/2602.04243](http://arxiv.org/abs/2602.04243)\n", "2602.04231": "- 2026-02-04, **GeoLanG: Geometry-Aware Language-Guided Grasping with Unified RGB-D Multimodal Learning**, Hongliang Ren Team, Paper: [http://arxiv.org/abs/2602.04231](http://arxiv.org/abs/2602.04231)\n", "2602.04228": "- 2026-02-04, **Reshaping Action Error Distributions for Reliable Vision-Language-Action Models**, Badong Chen Team, Paper: [http://arxiv.org/abs/2602.04228](http://arxiv.org/abs/2602.04228)\n", "2602.04215": "- 2026-02-04, **OAT: Ordered Action Tokenization**, Yilun Du Team, Paper: [http://arxiv.org/abs/2602.04215](http://arxiv.org/abs/2602.04215)\n", "2602.04213": "- 2026-02-04, **InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons**, Reid Simmons Team, Paper: [http://arxiv.org/abs/2602.04213](http://arxiv.org/abs/2602.04213)\n", "2602.04150": "- 2026-02-04, **A brief review of evolutionary game dynamics in the reinforcement learning paradigm**, Li Chen Team, Paper: [http://arxiv.org/abs/2602.04150](http://arxiv.org/abs/2602.04150)\n", "2602.04076": "- 2026-02-03, **Comparative Analysis of Autonomous Robotic and Manual Techniques for Ultrasonic Sacral Osteotomy: A Preliminary Study**, Farshid Alambeigi Team, Paper: [http://arxiv.org/abs/2602.04076](http://arxiv.org/abs/2602.04076)\n", "2602.03973": "- 2026-02-03, **VLS: Steering Pretrained Robot Policies via Vision-Language Models**, Ranjay Krishna Team, Paper: [http://arxiv.org/abs/2602.03973](http://arxiv.org/abs/2602.03973), Code: **[https://vision-language-steering.github.io/webpage/](https://vision-language-steering.github.io/webpage/)**\n", "2602.05468": "- 2026-02-05, **TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation**, Shigeki Sugano Team, Paper: [http://arxiv.org/abs/2602.05468](http://arxiv.org/abs/2602.05468)\n", "2602.05233": "- 2026-02-05, **MobileManiBench: Simplifying Model Verification for Mobile Manipulation**, Baining Guo Team, Paper: [http://arxiv.org/abs/2602.05233](http://arxiv.org/abs/2602.05233)\n", "2602.05049": "- 2026-02-04, **VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models**, Dongdong Chen Team, Paper: [http://arxiv.org/abs/2602.05049](http://arxiv.org/abs/2602.05049), Code: **[https://vista-vla.github.io/](https://vista-vla.github.io/)**\n", "2602.06864": "- 2026-02-06, **SURE: Safe Uncertainty-Aware Robot-Environment Interaction using Trajectory Optimization**, Majid Khadiv Team, Paper: [http://arxiv.org/abs/2602.06864](http://arxiv.org/abs/2602.06864)\n", "2602.06653": "- 2026-02-06, **RAPID: Reconfigurable, Adaptive Platform for Iterative Design**, Jia Liu Team, Paper: [http://arxiv.org/abs/2602.06653](http://arxiv.org/abs/2602.06653)\n", "2602.06620": "- 2026-02-06, **Force Generative Imitation Learning: Bridging Position Trajectory and Force Commands through Control Technique**, Toshiaki Tsuji Team, Paper: [http://arxiv.org/abs/2602.06620](http://arxiv.org/abs/2602.06620)\n", "2602.06572": "- 2026-02-06, **The Law of Task-Achieving Body Motion: Axiomatizing Success of Robot Manipulation Actions**, Michael Beetz Team, Paper: [http://arxiv.org/abs/2602.06572](http://arxiv.org/abs/2602.06572)\n", "2602.06512": "- 2026-02-06, **Beyond the Majority: Long-tail Imitation Learning for Robotic Manipulation**, Heng Tao Shen Team, Paper: [http://arxiv.org/abs/2602.06512](http://arxiv.org/abs/2602.06512)\n", "2602.06508": "- 2026-02-06, **World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy**, Mike Zheng Shou Team, Paper: [http://arxiv.org/abs/2602.06508](http://arxiv.org/abs/2602.06508)\n", "2602.06356": "- 2026-02-06, **Nipping the Drift in the Bud: Retrospective Rectification for Robust Vision-Language Navigation**, Weiying Xie Team, Paper: [http://arxiv.org/abs/2602.06356](http://arxiv.org/abs/2602.06356)\n", "2602.06273": "- 2026-02-06, **A High-Fidelity Robotic Manipulator Teleoperation Framework for Human-Centered Augmented Reality Evaluation**, Tian Guo Team, Paper: [http://arxiv.org/abs/2602.06273](http://arxiv.org/abs/2602.06273)\n"}, "VLM": {"2601.23281": "- 2026-01-30, **User Prompting Strategies and Prompt Enhancement Methods for Open-Set Object Detection in XR Environments**, Maria Gorlatova Team, Paper: [http://arxiv.org/abs/2601.23281](http://arxiv.org/abs/2601.23281)\n", "2601.23253": "- 2026-01-30, **Training-Free Test-Time Adaptation with Brownian Distance Covariance in Vision-Language Models**, Liang-Jie Zhang Team, Paper: [http://arxiv.org/abs/2601.23253](http://arxiv.org/abs/2601.23253)\n", "2601.23251": "- 2026-01-30, **Structured Over Scale: Learning Spatial Reasoning from Educational Video**, Sarah Ostadabbas Team, Paper: [http://arxiv.org/abs/2601.23251](http://arxiv.org/abs/2601.23251)\n", "2601.23149": "- 2026-01-30, **Hearing is Believing? Evaluating and Analyzing Audio Language Model Sycophancy with SYAUDIO**, Lijie Hu Team, Paper: [http://arxiv.org/abs/2601.23149](http://arxiv.org/abs/2601.23149)\n", "2601.23041": "- 2026-01-30, **One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs**, Dong Liu Team, Paper: [http://arxiv.org/abs/2601.23041](http://arxiv.org/abs/2601.23041)\n", "2601.22959": "- 2026-01-30, **Triage: Hierarchical Visual Budgeting for Efficient Video Reasoning in Vision-Language Models**, Jianzong Wang Team, Paper: [http://arxiv.org/abs/2601.22959](http://arxiv.org/abs/2601.22959)\n", "2601.22948": "- 2026-01-30, **Alignment among Language, Vision and Action Representations**, Stefano Nolfi Team, Paper: [http://arxiv.org/abs/2601.22948](http://arxiv.org/abs/2601.22948)\n", "2601.22830": "- 2026-01-30, **A Comparative Evaluation of Large Vision-Language Models for 2D Object Detection under SOTIF Conditions**, Arno Eichberger Team, Paper: [http://arxiv.org/abs/2601.22830](http://arxiv.org/abs/2601.22830)\n", "2601.22828": "- 2026-01-30, **Decomposing and Composing: Towards Efficient Vision-Language Continual Learning via Rank-1 Expert Pool in a Single LoRA**, Yinghuan Shi Team, Paper: [http://arxiv.org/abs/2601.22828](http://arxiv.org/abs/2601.22828)\n", "2601.22796": "- 2026-01-30, **HeatMat: Simulation of City Material Impact on Urban Heat Island Effect**, Rosalie Martin Team, Paper: [http://arxiv.org/abs/2601.22796](http://arxiv.org/abs/2601.22796)\n", "2601.22754": "- 2026-01-30, **Procedural Knowledge Extraction from Industrial Troubleshooting Guides Using Vision Language Models**, Christos Emmanouilidis Team, Paper: [http://arxiv.org/abs/2601.22754](http://arxiv.org/abs/2601.22754)\n", "2601.22738": "- 2026-01-30, **StreamSense: Streaming Social Task Detection with Selective Vision-Language Model Routing**, Roy Ka-Wei Lee Team, Paper: [http://arxiv.org/abs/2601.22738](http://arxiv.org/abs/2601.22738)\n", "2601.22737": "- 2026-01-30, **Lingua-SafetyBench: A Benchmark for Safety Evaluation of Multilingual Vision-Language Models**, Tat-Seng Chua Team, Paper: [http://arxiv.org/abs/2601.22737](http://arxiv.org/abs/2601.22737)\n", "2601.22714": "- 2026-01-30, **Vision-Language Models Unlock Task-Centric Latent Actions**, Vladislav Kurenkov Team, Paper: [http://arxiv.org/abs/2601.22714](http://arxiv.org/abs/2601.22714)\n", "2601.22709": "- 2026-01-30, **Gated Relational Alignment via Confidence-based Distillation for Efficient VLMs**, Yawei Li Team, Paper: [http://arxiv.org/abs/2601.22709](http://arxiv.org/abs/2601.22709)\n", "2601.22701": "- 2026-01-30, **Best-of-Q: Improving VLM agents with Q-function Action Ranking at Inference**, Kai Yuan Team, Paper: [http://arxiv.org/abs/2601.22701](http://arxiv.org/abs/2601.22701)\n", "2601.22696": "- 2026-01-30, **Bi-MCQ: Reformulating Vision-Language Alignment for Negation Understanding**, Hyun Gyu Lee Team, Paper: [http://arxiv.org/abs/2601.22696](http://arxiv.org/abs/2601.22696)\n", "2601.22570": "- 2026-01-30, **Leveraging Data to Say No: Memory Augmented Plug-and-Play Selective Prediction**, Nuno Vasconcelos Team, Paper: [http://arxiv.org/abs/2601.22570](http://arxiv.org/abs/2601.22570)\n", "2601.22451": "- 2026-01-30, **Countering the Over-Reliance Trap: Mitigating Object Hallucination for LVLMs via a Self-Validation Framework**, Jinsong Su Team, Paper: [http://arxiv.org/abs/2601.22451](http://arxiv.org/abs/2601.22451), Code: **[https://github.com/Liushiyu-0709/SelfVal](https://github.com/Liushiyu-0709/SelfVal)**\n", "2601.22398": "- 2026-01-29, **Jailbreaks on Vision Language Model via Multimodal Reasoning**, Yuguang Yao Team, Paper: [http://arxiv.org/abs/2601.22398](http://arxiv.org/abs/2601.22398)\n", "2602.02456": "- 2026-02-02, **Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning**, Kostas Alexis Team, Paper: [http://arxiv.org/abs/2602.02456](http://arxiv.org/abs/2602.02456)\n", "2602.02454": "- 2026-02-02, **World-Gymnast: Training Robots with Reinforcement Learning in a World Model**, Sherry Yang Team, Paper: [http://arxiv.org/abs/2602.02454](http://arxiv.org/abs/2602.02454), Code: **[https://world-gymnast.github.io/](https://world-gymnast.github.io/)**\n", "2602.02408": "- 2026-02-02, **ReasonEdit: Editing Vision-Language Models using Human Reasoning**, Thomas Hartvigsen Team, Paper: [http://arxiv.org/abs/2602.02408](http://arxiv.org/abs/2602.02408)\n", "2602.02341": "- 2026-02-02, **LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization**, Limin Wang Team, Paper: [http://arxiv.org/abs/2602.02341](http://arxiv.org/abs/2602.02341)\n", "2602.02063": "- 2026-02-02, **See2Refine: Vision-Language Feedback Improves LLM-Based eHMI Action Designers**, Takeo Igarashi Team, Paper: [http://arxiv.org/abs/2602.02063](http://arxiv.org/abs/2602.02063)\n", "2602.02043": "- 2026-02-02, **Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models**, Toshihiko Yamasaki Team, Paper: [http://arxiv.org/abs/2602.02043](http://arxiv.org/abs/2602.02043)\n", "2602.02014": "- 2026-02-02, **Rethinking Genomic Modeling Through Optical Character Recognition**, Xiangxiang Zeng Team, Paper: [http://arxiv.org/abs/2602.02014](http://arxiv.org/abs/2602.02014)\n", "2602.01984": "- 2026-02-02, **Enhancing Multi-Image Understanding through Delimiter Token Scaling**, Junsuk Choe Team, Paper: [http://arxiv.org/abs/2602.01984](http://arxiv.org/abs/2602.01984)\n", "2602.01915": "- 2026-02-02, **VLM-Guided Experience Replay**, Shie Mannor Team, Paper: [http://arxiv.org/abs/2602.01915](http://arxiv.org/abs/2602.01915)\n", "2602.01836": "- 2026-02-02, **Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery**, J. Marius Z\u00f6llner Team, Paper: [http://arxiv.org/abs/2602.01836](http://arxiv.org/abs/2602.01836)\n", "2602.01785": "- 2026-02-02, **CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding**, Xiaodong Gu Team, Paper: [http://arxiv.org/abs/2602.01785](http://arxiv.org/abs/2602.01785), Code: **[https://github.com/YerbaPage/CodeOCR](https://github.com/YerbaPage/CodeOCR)**\n", "2602.01738": "- 2026-02-02, **Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models**, Bin Li Team, Paper: [http://arxiv.org/abs/2602.01738](http://arxiv.org/abs/2602.01738)\n", "2602.01662": "- 2026-02-02, **AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act**, Yu She Team, Paper: [http://arxiv.org/abs/2602.01662](http://arxiv.org/abs/2602.01662)\n", "2602.01639": "- 2026-02-02, **ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval**, Tat-Seng Chua Team, Paper: [http://arxiv.org/abs/2602.01639](http://arxiv.org/abs/2602.01639)\n", "2602.01624": "- 2026-02-02, **PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards**, Mei Chen Team, Paper: [http://arxiv.org/abs/2602.01624](http://arxiv.org/abs/2602.01624)\n", "2602.01576": "- 2026-02-02, **Generative Visual Code Mobile World Models**, Jamin Shin Team, Paper: [http://arxiv.org/abs/2602.01576](http://arxiv.org/abs/2602.01576)\n", "2602.01574": "- 2026-02-02, **SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models**, Xiaochun Cao Team, Paper: [http://arxiv.org/abs/2602.01574](http://arxiv.org/abs/2602.01574)\n", "2602.01530": "- 2026-02-02, **Preserving Localized Patch Semantics in VLMs**, Longin Jan Latecki Team, Paper: [http://arxiv.org/abs/2602.01530](http://arxiv.org/abs/2602.01530)\n", "2602.01527": "- 2026-02-02, **Toward a Machine Bertin: Why Visualization Needs Design Principles for Machine Cognition**, Brian Keith-Norambuena Team, Paper: [http://arxiv.org/abs/2602.01527](http://arxiv.org/abs/2602.01527)\n", "2602.01452": "- 2026-02-01, **Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles**, Jiachen Bian Team, Paper: [http://arxiv.org/abs/2602.01452](http://arxiv.org/abs/2602.01452)\n", "2602.03822": "- 2026-02-03, **They Said Memes Were Harmless-We Found the Ones That Hurt: Decoding Jokes, Symbols, and Cultural References**, Usman Naseem Team, Paper: [http://arxiv.org/abs/2602.03822](http://arxiv.org/abs/2602.03822)\n", "2602.03750": "- 2026-02-03, **Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives**, Katherine D. Van Schaik Team, Paper: [http://arxiv.org/abs/2602.03750](http://arxiv.org/abs/2602.03750)\n", "2602.03742": "- 2026-02-03, **Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment**, Mahdi Abdelguerfi Team, Paper: [http://arxiv.org/abs/2602.03742](http://arxiv.org/abs/2602.03742)\n", "2602.03733": "- 2026-02-03, **RegionReasoner: Region-Grounded Multi-Round Visual Reasoning**, Cees G. M. Snoek Team, Paper: [http://arxiv.org/abs/2602.03733](http://arxiv.org/abs/2602.03733)\n", "2602.03665": "- 2026-02-03, **MM-SCALE: Grounded Multimodal Moral Reasoning via Scalar Judgment and Listwise Alignment**, Gunhee Kim Team, Paper: [http://arxiv.org/abs/2602.03665](http://arxiv.org/abs/2602.03665)\n", "2602.03615": "- 2026-02-03, **KTV: Keyframes and Key Tokens Selection for Efficient Training-Free Video LLMs**, Jianyuan Guo Team, Paper: [http://arxiv.org/abs/2602.03615](http://arxiv.org/abs/2602.03615)\n", "2602.03594": "- 2026-02-03, **TIPS Over Tricks: Simple Prompts for Effective Zero-shot Anomaly Detection**, Mohammad Sabokrou Team, Paper: [http://arxiv.org/abs/2602.03594](http://arxiv.org/abs/2602.03594)\n", "2602.03530": "- 2026-02-03, **Interpretable Logical Anomaly Classification via Constraint Decomposition and Instruction Fine-Tuning**, Jianxiong Wang Team, Paper: [http://arxiv.org/abs/2602.03530](http://arxiv.org/abs/2602.03530)\n", "2602.03491": "- 2026-02-03, **Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance**, Min Zhang Team, Paper: [http://arxiv.org/abs/2602.03491](http://arxiv.org/abs/2602.03491)\n", "2602.03454": "- 2026-02-03, **Contextualized Visual Personalization in Vision-Language Models**, Sungroh Yoon Team, Paper: [http://arxiv.org/abs/2602.03454](http://arxiv.org/abs/2602.03454), Code: **[https://github.com/oyt9306/CoViP](https://github.com/oyt9306/CoViP)**\n", "2602.03416": "- 2026-02-03, **AesRec: A Dataset for Aesthetics-Aligned Clothing Outfit Recommendation**, Jimmy Xiangji Huang Team, Paper: [http://arxiv.org/abs/2602.03416](http://arxiv.org/abs/2602.03416)\n", "2602.03402": "- 2026-02-03, **Risk Awareness Injection: Calibrating Vision-Language Models for Safety without Compromising Utility**, Ming Li Team, Paper: [http://arxiv.org/abs/2602.03402](http://arxiv.org/abs/2602.03402)\n", "2602.03295": "- 2026-02-03, **POP: Prefill-Only Pruning for Efficient Large Model Inference**, Qingan Li Team, Paper: [http://arxiv.org/abs/2602.03295](http://arxiv.org/abs/2602.03295)\n", "2602.03253": "- 2026-02-03, **LaVPR: Benchmarking Language and Vision for Place Recognition**, Yoli Shavit Team, Paper: [http://arxiv.org/abs/2602.03253](http://arxiv.org/abs/2602.03253)\n", "2602.03151": "- 2026-02-03, **Enhancing Foundation VLM Robustness to Missing Modality: Scalable Diffusion for Bi-directional Feature Restoration**, Haixia Bi Team, Paper: [http://arxiv.org/abs/2602.03151](http://arxiv.org/abs/2602.03151)\n", "2602.03134": "- 2026-02-03, **SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass**, Xin Miao Team, Paper: [http://arxiv.org/abs/2602.03134](http://arxiv.org/abs/2602.03134)\n", "2602.03130": "- 2026-02-03, **FinMTM: A Multi-Turn Multimodal Benchmark for Financial Reasoning and Agent Evaluation**, Rongjunchen Zhang Team, Paper: [http://arxiv.org/abs/2602.03130](http://arxiv.org/abs/2602.03130)\n", "2602.03119": "- 2026-02-03, **Function-Space Empirical Bayes Regularisation with Large Vision-Language Model Priors**, Wenbo Ding Team, Paper: [http://arxiv.org/abs/2602.03119](http://arxiv.org/abs/2602.03119)\n", "2602.03060": "- 2026-02-03, **IVC-Prune: Revealing the Implicit Visual Coordinates in LVLMs for Vision Token Pruning**, Yongchao Xu Team, Paper: [http://arxiv.org/abs/2602.03060](http://arxiv.org/abs/2602.03060)\n", "2602.03038": "- 2026-02-03, **Bongards at the Boundary of Perception and Reasoning: Programs or Language?**, Kevin Ellis Team, Paper: [http://arxiv.org/abs/2602.03038](http://arxiv.org/abs/2602.03038)\n", "2602.04864": "- 2026-02-04, **When LLaVA Meets Objects: Token Composition for Vision-Language-Models**, Hilde Kuehne Team, Paper: [http://arxiv.org/abs/2602.04864](http://arxiv.org/abs/2602.04864)\n", "2602.04849": "- 2026-02-04, **El Agente Estructural: An Artificially Intelligent Molecular Editor**, Varinia Bernales Team, Paper: [http://arxiv.org/abs/2602.04849](http://arxiv.org/abs/2602.04849)\n", "2602.04802": "- 2026-02-04, **VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?**, Huchuan Lu Team, Paper: [http://arxiv.org/abs/2602.04802](http://arxiv.org/abs/2602.04802)\n", "2602.04699": "- 2026-02-04, **Annotation Free Spacecraft Detection and Segmentation using Vision Language Models**, Djamila Aouada Team, Paper: [http://arxiv.org/abs/2602.04699](http://arxiv.org/abs/2602.04699)\n", "2602.04672": "- 2026-02-04, **AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation**, Chunhua Shen Team, Paper: [http://arxiv.org/abs/2602.04672](http://arxiv.org/abs/2602.04672)\n", "2602.04657": "- 2026-02-04, **PIO-FVLM: Rethinking Training-Free Visual Token Reduction for VLM Acceleration from an Inference-Objective Perspective**, Chunhua Shen Team, Paper: [http://arxiv.org/abs/2602.04657](http://arxiv.org/abs/2602.04657)\n", "2602.04635": "- 2026-02-04, **Relational Scene Graphs for Object Grounding of Natural Language Commands**, Ville Kyrki Team, Paper: [http://arxiv.org/abs/2602.04635](http://arxiv.org/abs/2602.04635)\n", "2602.04617": "- 2026-02-04, **LEAD: Layer-wise Expert-aligned Decoding for Faithful Radiology Report Generation**, Yan Song Team, Paper: [http://arxiv.org/abs/2602.04617](http://arxiv.org/abs/2602.04617)\n", "2602.04587": "- 2026-02-04, **VILLAIN at AVerImaTeC: Verifying Image-Text Claims via Multi-Agent Collaboration**, Kunwoo Park Team, Paper: [http://arxiv.org/abs/2602.04587](http://arxiv.org/abs/2602.04587)\n", "2602.04565": "- 2026-02-04, **Understanding Degradation with Vision Language Model**, Xuelong Li Team, Paper: [http://arxiv.org/abs/2602.04565](http://arxiv.org/abs/2602.04565)\n", "2602.04515": "- 2026-02-04, **EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models**, B\u00f6rje F. Karlsson Team, Paper: [http://arxiv.org/abs/2602.04515](http://arxiv.org/abs/2602.04515)\n", "2602.04356": "- 2026-02-04, **When and Where to Attack? Stage-wise Attention-Guided Adversarial Attack on Large Vision Language Models**, Se-Young Yun Team, Paper: [http://arxiv.org/abs/2602.04356](http://arxiv.org/abs/2602.04356)\n", "2602.04355": "- 2026-02-04, **Can Vision Replace Text in Working Memory? Evidence from Spatial n-Back in Vision-Language Models**, Deyu Zhou Team, Paper: [http://arxiv.org/abs/2602.04355](http://arxiv.org/abs/2602.04355)\n", "2602.04340": "- 2026-02-04, **Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning**, Shu-Tao Xia Team, Paper: [http://arxiv.org/abs/2602.04340](http://arxiv.org/abs/2602.04340)\n", "2602.04337": "- 2026-02-04, **Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner**, Shu-Tao Xia Team, Paper: [http://arxiv.org/abs/2602.04337](http://arxiv.org/abs/2602.04337)\n", "2602.04304": "- 2026-02-04, **Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement**, Lin Gui Team, Paper: [http://arxiv.org/abs/2602.04304](http://arxiv.org/abs/2602.04304)\n", "2602.04256": "- 2026-02-04, **AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models**, Yunjiang Lou Team, Paper: [http://arxiv.org/abs/2602.04256](http://arxiv.org/abs/2602.04256)\n", "2602.04094": "- 2026-02-04, **VideoBrain: Learning Adaptive Frame Sampling for Long Video Understanding**, Weining Shen Team, Paper: [http://arxiv.org/abs/2602.04094](http://arxiv.org/abs/2602.04094)\n", "2602.03983": "- 2026-02-03, **Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement**, Rex Ying Team, Paper: [http://arxiv.org/abs/2602.03983](http://arxiv.org/abs/2602.03983)\n", "2602.03973": "- 2026-02-03, **VLS: Steering Pretrained Robot Policies via Vision-Language Models**, Ranjay Krishna Team, Paper: [http://arxiv.org/abs/2602.03973](http://arxiv.org/abs/2602.03973), Code: **[https://vision-language-steering.github.io/webpage/](https://vision-language-steering.github.io/webpage/)**\n", "2602.06033": "- 2026-02-05, **Can vision language models learn intuitive physics from interaction?**, Eric Schulz Team, Paper: [http://arxiv.org/abs/2602.06033](http://arxiv.org/abs/2602.06033)\n", "2602.06013": "- 2026-02-05, **GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?**, Jiaqi Wang Team, Paper: [http://arxiv.org/abs/2602.06013](http://arxiv.org/abs/2602.06013), Code: **[https://genarena.github.io/](https://genarena.github.io/)**\n", "2602.05809": "- 2026-02-05, **Focus-Scan-Refine: From Human Visual Perception to Efficient Visual Token Pruning**, Xianming Liu Team, Paper: [http://arxiv.org/abs/2602.05809](http://arxiv.org/abs/2602.05809)\n", "2602.05789": "- 2026-02-05, **Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation**, Weiming Zhang Team, Paper: [http://arxiv.org/abs/2602.05789](http://arxiv.org/abs/2602.05789)\n", "2602.05710": "- 2026-02-05, **Ethology of Latent Spaces**, Philippe Boisnard Team, Paper: [http://arxiv.org/abs/2602.05710](http://arxiv.org/abs/2602.05710), Code: **[https://paragraphe.univ-paris8.fr/IMG/pdf/programme_colloque_his9_campuscondorcet_v3.pdf](https://paragraphe.univ-paris8.fr/IMG/pdf/programme_colloque_his9_campuscondorcet_v3.pdf)**\n", "2602.05578": "- 2026-02-05, **LoGoSeg: Integrating Local and Global Features for Open-Vocabulary Semantic Segmentation**, Yiguo Qiao Team, Paper: [http://arxiv.org/abs/2602.05578](http://arxiv.org/abs/2602.05578)\n", "2602.05570": "- 2026-02-05, **TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?**, Cheston Tan Team, Paper: [http://arxiv.org/abs/2602.05570](http://arxiv.org/abs/2602.05570)\n", "2602.05552": "- 2026-02-05, **VLN-Pilot: Large Vision-Language Model as an Autonomous Indoor Drone Operator**, Miguel Cazorla Team, Paper: [http://arxiv.org/abs/2602.05552](http://arxiv.org/abs/2602.05552)\n", "2602.05535": "- 2026-02-05, **Detecting Misbehaviors of Large Vision-Language Models by Evidential Uncertainty Quantification**, Liping Jing Team, Paper: [http://arxiv.org/abs/2602.05535](http://arxiv.org/abs/2602.05535), Code: **[https://github.com/HT86159/EUQ](https://github.com/HT86159/EUQ)**\n", "2602.05437": "- 2026-02-05, **Once Correct, Still Wrong: Counterfactual Hallucination in Multilingual Vision-Language Models**, Nadir Durrani Team, Paper: [http://arxiv.org/abs/2602.05437](http://arxiv.org/abs/2602.05437)\n", "2602.05384": "- 2026-02-05, **Dolphin-v2: Universal Document Parsing via Scalable Anchor Prompting**, Can Huang Team, Paper: [http://arxiv.org/abs/2602.05384](http://arxiv.org/abs/2602.05384)\n", "2602.05382": "- 2026-02-05, **VRIQ: Benchmarking and Analyzing Visual-Reasoning IQ of VLMs**, Konstantinos Psounis Team, Paper: [http://arxiv.org/abs/2602.05382](http://arxiv.org/abs/2602.05382)\n", "2602.05273": "- 2026-02-05, **Affordance-Aware Interactive Decision-Making and Execution for Ambiguous Instructions**, Tao Zhang Team, Paper: [http://arxiv.org/abs/2602.05273](http://arxiv.org/abs/2602.05273)\n", "2602.05261": "- 2026-02-05, **Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR**, Haibo Qiu Team, Paper: [http://arxiv.org/abs/2602.05261](http://arxiv.org/abs/2602.05261)\n", "2602.05202": "- 2026-02-05, **GT-SVJ: Generative-Transformer-Based Self-Supervised Video Judge For Efficient Video Reward Modeling**, Tong Zhang Team, Paper: [http://arxiv.org/abs/2602.05202](http://arxiv.org/abs/2602.05202)\n", "2602.05132": "- 2026-02-04, **ARGaze: Autoregressive Transformers for Online Egocentric Gaze Estimation**, Yapeng Tian Team, Paper: [http://arxiv.org/abs/2602.05132](http://arxiv.org/abs/2602.05132)\n", "2602.05049": "- 2026-02-04, **VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models**, Dongdong Chen Team, Paper: [http://arxiv.org/abs/2602.05049](http://arxiv.org/abs/2602.05049), Code: **[https://vista-vla.github.io/](https://vista-vla.github.io/)**\n", "2602.05023": "- 2026-02-04, **Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?**, Alan Ritter Team, Paper: [http://arxiv.org/abs/2602.05023](http://arxiv.org/abs/2602.05023)\n", "2602.06822": "- 2026-02-06, **POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models**, Joo-Young Kim Team, Paper: [http://arxiv.org/abs/2602.06822](http://arxiv.org/abs/2602.06822)\n", "2602.06652": "- 2026-02-06, **Same Answer, Different Representations: Hidden instability in VLMs**, Pasquale Minervini Team, Paper: [http://arxiv.org/abs/2602.06652](http://arxiv.org/abs/2602.06652)\n", "2602.06619": "- 2026-02-06, **CauCLIP: Bridging the Sim-to-Real Gap in Surgical Video Understanding via Causality-Inspired Vision-Language Modeling**, Cheng Xue Team, Paper: [http://arxiv.org/abs/2602.06619](http://arxiv.org/abs/2602.06619)\n", "2602.06566": "- 2026-02-06, **SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs**, Mattia Rigotti Team, Paper: [http://arxiv.org/abs/2602.06566](http://arxiv.org/abs/2602.06566)\n", "2602.06530": "- 2026-02-06, **Universal Anti-forensics Attack against Image Forgery Detection via Multi-modal Guidance**, Anastasia Antsiferova Team, Paper: [http://arxiv.org/abs/2602.06530](http://arxiv.org/abs/2602.06530)\n", "2602.06507": "- 2026-02-06, **FloorplanVLM: A Vision-Language Model for Floorplan Vectorization**, Yue Yang Team, Paper: [http://arxiv.org/abs/2602.06507](http://arxiv.org/abs/2602.06507)\n", "2602.06402": "- 2026-02-06, **MeDocVL: A Visual Language Model for Medical Document Understanding and Parsing**, Hong Li Team, Paper: [http://arxiv.org/abs/2602.06402](http://arxiv.org/abs/2602.06402)\n", "2602.06391": "- 2026-02-06, **POINTS-GUI-G: GUI-Grounding Journey**, Jie Zhou Team, Paper: [http://arxiv.org/abs/2602.06391](http://arxiv.org/abs/2602.06391)\n", "2602.06218": "- 2026-02-05, **Cross-Modal Redundancy and the Geometry of Vision-Language Embeddings**, Agustin Picard Team, Paper: [http://arxiv.org/abs/2602.06218](http://arxiv.org/abs/2602.06218)\n", "2602.06195": "- 2026-02-05, **DeDPO: Debiased Direct Preference Optimization for Diffusion Models**, Ramin Zabih Team, Paper: [http://arxiv.org/abs/2602.06195](http://arxiv.org/abs/2602.06195)\n", "2602.06184": "- 2026-02-05, **PhenoLIP: Integrating Phenotype Ontology Knowledge into Medical Vision-Language Pretraining**, Weidi Xie Team, Paper: [http://arxiv.org/abs/2602.06184](http://arxiv.org/abs/2602.06184)\n", "2602.06127": "- 2026-02-05, **Compressing LLMs with MoP: Mixture of Pruners**, Artur Jordao Team, Paper: [http://arxiv.org/abs/2602.06127](http://arxiv.org/abs/2602.06127), Code: **[https://github.com/c2d-usp/Efficient-LLMs-with-MoP](https://github.com/c2d-usp/Efficient-LLMs-with-MoP)**\n"}, "VLA": {"2601.22714": "- 2026-01-30, **Vision-Language Models Unlock Task-Centric Latent Actions**, Vladislav Kurenkov Team, Paper: [http://arxiv.org/abs/2601.22714](http://arxiv.org/abs/2601.22714)\n", "2601.22467": "- 2026-01-30, **CARE: Multi-Task Pretraining for Latent Continuous Action Representation in Robot Control**, Jianzong Wang Team, Paper: [http://arxiv.org/abs/2601.22467](http://arxiv.org/abs/2601.22467)\n", "2601.22153": "- 2026-01-29, **DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation**, Ziwei Liu Team, Paper: [http://arxiv.org/abs/2601.22153](http://arxiv.org/abs/2601.22153), Code: **[https://www.infinitescript.com/project/dynamic-vla/](https://www.infinitescript.com/project/dynamic-vla/)**\n", "2601.21971": "- 2026-01-29, **MoE-ACT: Improving Surgical Imitation Learning Policies through Supervised Mixture-of-Experts**, Stefanie Speidel Team, Paper: [http://arxiv.org/abs/2601.21971](http://arxiv.org/abs/2601.21971)\n", "2601.21712": "- 2026-01-29, **CoFreeVLA: Collision-Free Dual-Arm Manipulation via Vision-Language-Action Model and Risk Estimation**, Yaohua Liu Team, Paper: [http://arxiv.org/abs/2601.21712](http://arxiv.org/abs/2601.21712)\n", "2601.21602": "- 2026-01-29, **AIR-VLA: Vision-Language-Action Systems for Aerial Manipulation**, Yonglin Tian Team, Paper: [http://arxiv.org/abs/2601.21602](http://arxiv.org/abs/2601.21602)\n", "2601.21506": "- 2026-01-29, **IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation**, Jeonggil Ko Team, Paper: [http://arxiv.org/abs/2601.21506](http://arxiv.org/abs/2601.21506)\n", "2601.20334": "- 2026-01-28, **Demonstration-Free Robotic Control via LLM Agents**, Tiffany J. Hwu Team, Paper: [http://arxiv.org/abs/2601.20334](http://arxiv.org/abs/2601.20334)\n", "2601.20321": "- 2026-01-30, **TaF-VLA: Tactile-Force Alignment in Vision-Language-Action Models for Force-aware Manipulation**, Ziyuan Jiao Team, Paper: [http://arxiv.org/abs/2601.20321](http://arxiv.org/abs/2601.20321)\n", "2601.20262": "- 2026-01-28, **Shallow-\u03c0: Knowledge Distillation for Flow-based VLAs**, Taehan Kim Team, Paper: [http://arxiv.org/abs/2601.20262](http://arxiv.org/abs/2601.20262)\n", "2601.19634": "- 2026-01-27, **AC^2-VLA: Action-Context-Aware Adaptive Computation in Vision-Language-Action Models for Efficient Robotic Manipulation**, Lei Zhu Team, Paper: [http://arxiv.org/abs/2601.19634](http://arxiv.org/abs/2601.19634)\n", "2601.18723": "- 2026-01-26, **Trustworthy Evaluation of Robotic Manipulation: A New Benchmark and AutoEval Methods**, Hong Liu Team, Paper: [http://arxiv.org/abs/2601.18723](http://arxiv.org/abs/2601.18723)\n", "2601.18692": "- 2026-01-26, **A Pragmatic VLA Foundation Model**, Kecheng Zheng Team, Paper: [http://arxiv.org/abs/2601.18692](http://arxiv.org/abs/2601.18692), Code: **[https://technology.robbyant.com/lingbot-vla/](https://technology.robbyant.com/lingbot-vla/)**\n", "2601.18323": "- 2026-01-26, **TC-IDM: Grounding Video Generation for Executable Zero-shot Robot Motion**, Jian Tang Team, Paper: [http://arxiv.org/abs/2601.18323](http://arxiv.org/abs/2601.18323)\n", "2601.17885": "- 2026-01-25, **PEAfowl: Perception-Enhanced Multi-View Vision-Language-Action for Bimanual Manipulation**, Xun Cao Team, Paper: [http://arxiv.org/abs/2601.17885](http://arxiv.org/abs/2601.17885)\n", "2601.17657": "- 2026-01-25, **SPACE-CLIP: Spatial Perception via Adaptive CLIP Embeddings for Monocular Depth Estimation**, Andrew Jaeyong Choi Team, Paper: [http://arxiv.org/abs/2601.17657](http://arxiv.org/abs/2601.17657)\n", "2601.16667": "- 2026-01-23, **ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance**, Wei-Shi Zheng Team, Paper: [http://arxiv.org/abs/2601.16667](http://arxiv.org/abs/2601.16667)\n", "2601.16409": "- 2026-01-23, **Gen-DBA: Generative Database Agents (Towards a Move 37 for Databases)**, Walid G. Aref Team, Paper: [http://arxiv.org/abs/2601.16409](http://arxiv.org/abs/2601.16409)\n", "2601.16207": "- 2026-01-22, **IVRA: Improving Visual-Token Relations for Robot Action Policy with Training-Free Hint-Based Guidance**, Michael S Ryoo Team, Paper: [http://arxiv.org/abs/2601.16207](http://arxiv.org/abs/2601.16207)\n", "2601.16163": "- 2026-01-22, **Cosmos Policy: Fine-Tuning Video Models for Visuomotor Control and Planning**, Jinwei Gu Team, Paper: [http://arxiv.org/abs/2601.16163](http://arxiv.org/abs/2601.16163)\n", "2602.02459": "- 2026-02-02, **TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments**, Jiaqi Ma Team, Paper: [http://arxiv.org/abs/2602.02459](http://arxiv.org/abs/2602.02459)\n", "2602.02454": "- 2026-02-02, **World-Gymnast: Training Robots with Reinforcement Learning in a World Model**, Sherry Yang Team, Paper: [http://arxiv.org/abs/2602.02454](http://arxiv.org/abs/2602.02454), Code: **[https://world-gymnast.github.io/](https://world-gymnast.github.io/)**\n", "2602.02212": "- 2026-02-02, **MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models**, Lemiao Qiu Team, Paper: [http://arxiv.org/abs/2602.02212](http://arxiv.org/abs/2602.02212)\n", "2602.02142": "- 2026-02-02, **FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation**, Haiyue Zhu Team, Paper: [http://arxiv.org/abs/2602.02142](http://arxiv.org/abs/2602.02142)\n", "2602.01834": "- 2026-02-02, **Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models**, Di Wang Team, Paper: [http://arxiv.org/abs/2602.01834](http://arxiv.org/abs/2602.01834)\n", "2602.01811": "- 2026-02-02, **From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models**, Jianzong Wang Team, Paper: [http://arxiv.org/abs/2602.01811](http://arxiv.org/abs/2602.01811)\n", "2602.01166": "- 2026-02-01, **Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models**, Shanghang Zhang Team, Paper: [http://arxiv.org/abs/2602.01166](http://arxiv.org/abs/2602.01166)\n", "2602.01158": "- 2026-02-01, **Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs**, Matteo Matteucci Team, Paper: [http://arxiv.org/abs/2602.01158](http://arxiv.org/abs/2602.01158)\n", "2602.01100": "- 2026-02-01, **StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating**, Lu Fang Team, Paper: [http://arxiv.org/abs/2602.01100](http://arxiv.org/abs/2602.01100)\n", "2602.01067": "- 2026-02-01, **A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation**, Jose Barreiros Team, Paper: [http://arxiv.org/abs/2602.01067](http://arxiv.org/abs/2602.01067)\n", "2602.00919": "- 2026-01-31, **Green-VLA: Staged Vision-Language-Action Model for Generalist Robots**, A. Postnikov Team, Paper: [http://arxiv.org/abs/2602.00919](http://arxiv.org/abs/2602.00919)\n", "2602.00807": "- 2026-01-31, **Any3D-VLA: Enhancing VLA Robustness via Diverse Point Clouds**, Hengshuang Zhao Team, Paper: [http://arxiv.org/abs/2602.00807](http://arxiv.org/abs/2602.00807)\n", "2602.00780": "- 2026-01-31, **Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models**, Yanyong Zhang Team, Paper: [http://arxiv.org/abs/2602.00780](http://arxiv.org/abs/2602.00780)\n", "2602.00743": "- 2026-01-31, **SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning**, Ivor Tsang Team, Paper: [http://arxiv.org/abs/2602.00743](http://arxiv.org/abs/2602.00743)\n", "2602.00686": "- 2026-01-31, **Learning to Accelerate Vision-Language-Action Models through Adaptive Visual Token Caching**, Shuo Yang Team, Paper: [http://arxiv.org/abs/2602.00686](http://arxiv.org/abs/2602.00686)\n", "2602.00557": "- 2026-01-31, **ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation**, Shuo Yang Team, Paper: [http://arxiv.org/abs/2602.00557](http://arxiv.org/abs/2602.00557)\n", "2602.00500": "- 2026-01-31, **Inject Once Survive Later: Backdooring Vision-Language-Action Models to Persist Through Downstream Fine-tuning**, Shuo Yang Team, Paper: [http://arxiv.org/abs/2602.00500](http://arxiv.org/abs/2602.00500)\n", "2602.03782": "- 2026-02-03, **QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization**, Zhipeng Zhang Team, Paper: [http://arxiv.org/abs/2602.03782](http://arxiv.org/abs/2602.03782)\n", "2602.03668": "- 2026-02-03, **MVP-LAM: Learning Action-Centric Latent Action via Cross-Viewpoint Reconstruction**, Jungwoo Lee Team, Paper: [http://arxiv.org/abs/2602.03668](http://arxiv.org/abs/2602.03668)\n", "2602.03445": "- 2026-02-03, **CRL-VLA: Continual Vision-Language-Action Learning**, Chao Huang Team, Paper: [http://arxiv.org/abs/2602.03445](http://arxiv.org/abs/2602.03445)\n", "2602.03310": "- 2026-02-03, **RDT2: Exploring the Scaling Limit of UMI Data Towards Zero-Shot Cross-Embodiment Generalization**, Jun Zhu Team, Paper: [http://arxiv.org/abs/2602.03310](http://arxiv.org/abs/2602.03310)\n", "2602.03153": "- 2026-02-03, **When Attention Betrays: Erasing Backdoor Attacks in Robotic Policies by Reconstructing Visual Tokens**, Miao Li Team, Paper: [http://arxiv.org/abs/2602.03153](http://arxiv.org/abs/2602.03153)\n", "2602.02864": "- 2026-02-02, **Accelerating Structured Chain-of-Thought in Autonomous Vehicles**, Marco Pavone Team, Paper: [http://arxiv.org/abs/2602.02864](http://arxiv.org/abs/2602.02864)\n", "2602.04600": "- 2026-02-04, **Act, Sense, Act: Learning Non-Markovian Active Perception Strategies from Large-Scale Egocentric Human Data**, Wenzhao Lian Team, Paper: [http://arxiv.org/abs/2602.04600](http://arxiv.org/abs/2602.04600)\n", "2602.04315": "- 2026-02-04, **GeneralVLA: Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning**, Hao Tang Team, Paper: [http://arxiv.org/abs/2602.04315](http://arxiv.org/abs/2602.04315)\n", "2602.04228": "- 2026-02-04, **Reshaping Action Error Distributions for Reliable Vision-Language-Action Models**, Badong Chen Team, Paper: [http://arxiv.org/abs/2602.04228](http://arxiv.org/abs/2602.04228)\n", "2602.04208": "- 2026-02-04, **SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models**, Jonghyun Choi Team, Paper: [http://arxiv.org/abs/2602.04208](http://arxiv.org/abs/2602.04208)\n", "2602.04184": "- 2026-02-04, **Natural Language Instructions for Scene-Responsive Human-in-the-Loop Motion Planning in Autonomous Driving using Vision-Language-Action Models**, Ross Greer Team, Paper: [http://arxiv.org/abs/2602.04184](http://arxiv.org/abs/2602.04184)\n", "2602.03983": "- 2026-02-03, **Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement**, Rex Ying Team, Paper: [http://arxiv.org/abs/2602.03983](http://arxiv.org/abs/2602.03983)\n", "2602.05765": "- 2026-02-05, **RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism**, Junwu Xiong Team, Paper: [http://arxiv.org/abs/2602.05765](http://arxiv.org/abs/2602.05765)\n", "2602.05441": "- 2026-02-05, **Benchmarking Affordance Generalization with BusyBox**, Galen Mullins Team, Paper: [http://arxiv.org/abs/2602.05441](http://arxiv.org/abs/2602.05441)\n", "2602.05325": "- 2026-02-05, **RoboPaint: From Human Demonstration to Any Robot and Any View**, Zhengxue Cheng Team, Paper: [http://arxiv.org/abs/2602.05325](http://arxiv.org/abs/2602.05325)\n", "2602.05233": "- 2026-02-05, **MobileManiBench: Simplifying Model Verification for Mobile Manipulation**, Baining Guo Team, Paper: [http://arxiv.org/abs/2602.05233](http://arxiv.org/abs/2602.05233)\n", "2602.05049": "- 2026-02-04, **VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models**, Dongdong Chen Team, Paper: [http://arxiv.org/abs/2602.05049](http://arxiv.org/abs/2602.05049), Code: **[https://vista-vla.github.io/](https://vista-vla.github.io/)**\n", "2602.06620": "- 2026-02-06, **Force Generative Imitation Learning: Bridging Position Trajectory and Force Commands through Control Technique**, Toshiaki Tsuji Team, Paper: [http://arxiv.org/abs/2602.06620](http://arxiv.org/abs/2602.06620)\n", "2602.06575": "- 2026-02-06, **Think Proprioceptively: Embodied Visual Reasoning for VLA Manipulation**, Guodong Guo Team, Paper: [http://arxiv.org/abs/2602.06575](http://arxiv.org/abs/2602.06575)\n", "2602.06556": "- 2026-02-06, **LIBERO-X: Robustness Litmus for Vision-Language-Action Models**, Xinmin Liu Team, Paper: [http://arxiv.org/abs/2602.06556](http://arxiv.org/abs/2602.06556)\n", "2602.06521": "- 2026-02-06, **DriveWorld-VLA: Unified Latent-Space World Modeling with Vision-Language-Action for Autonomous Driving**, Long Chen Team, Paper: [http://arxiv.org/abs/2602.06521](http://arxiv.org/abs/2602.06521)\n", "2602.06508": "- 2026-02-06, **World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy**, Mike Zheng Shou Team, Paper: [http://arxiv.org/abs/2602.06508](http://arxiv.org/abs/2602.06508)\n", "2602.06339": "- 2026-02-06, **Action Hallucination in Generative Visual-Language-Action Models**, Eugene Lim Team, Paper: [http://arxiv.org/abs/2602.06339](http://arxiv.org/abs/2602.06339)\n"}, "Humanoid": {"2601.23080": "- 2026-01-30, **Robust and Generalized Humanoid Motion Tracking**, Dongdong Zheng Team, Paper: [http://arxiv.org/abs/2601.23080](http://arxiv.org/abs/2601.23080)\n", "2601.22517": "- 2026-01-30, **RoboStriker: Hierarchical Decision-Making for Autonomous Humanoid Boxing**, Weinan Zhang Team, Paper: [http://arxiv.org/abs/2601.22517](http://arxiv.org/abs/2601.22517)\n", "2601.18975": "- 2026-01-26, **HumanoidTurk: Expanding VR Haptics with Humanoids for Driving Simulations**, Jin-Hyuk Hong Team, Paper: [http://arxiv.org/abs/2601.18975](http://arxiv.org/abs/2601.18975)\n", "2601.18963": "- 2026-01-26, **Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot**, Josh Merel Team, Paper: [http://arxiv.org/abs/2601.18963](http://arxiv.org/abs/2601.18963)\n", "2601.17507": "- 2026-01-24, **MetaWorld: Skill Transfer and Composition in a Hierarchical World Model for Grounding High-Level Instructions**, Tongtong Feng Team, Paper: [http://arxiv.org/abs/2601.17507](http://arxiv.org/abs/2601.17507)\n", "2601.17440": "- 2026-01-24, **PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes**, Hesheng Wang Team, Paper: [http://arxiv.org/abs/2601.17440](http://arxiv.org/abs/2601.17440)\n", "2601.17287": "- 2026-01-24, **Real-Time Synchronized Interaction Framework for Emotion-Aware Humanoid Robots**, Xihan Bian Team, Paper: [http://arxiv.org/abs/2601.17287](http://arxiv.org/abs/2601.17287)\n", "2601.15419": "- 2026-01-21, **Learning a Unified Latent Space for Cross-Embodiment Robot Control**, Dongheui Lee Team, Paper: [http://arxiv.org/abs/2601.15419](http://arxiv.org/abs/2601.15419)\n", "2601.14921": "- 2026-01-21, **Vision-Language Models on the Edge for Real-Time Robotic Perception**, Syed Ali Raza Zaidi Team, Paper: [http://arxiv.org/abs/2601.14921](http://arxiv.org/abs/2601.14921)\n", "2601.14874": "- 2026-01-21, **HumanoidVLM: Vision-Language-Guided Impedance Control for Contact-Rich Humanoid Manipulation**, Dzmitry Tsetserukou Team, Paper: [http://arxiv.org/abs/2601.14874](http://arxiv.org/abs/2601.14874)\n", "2601.12799": "- 2026-01-19, **FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions**, Xipeng Qiu Team, Paper: [http://arxiv.org/abs/2601.12799](http://arxiv.org/abs/2601.12799), Code: **[https://openmoss.github.io/FRoM-W1](https://openmoss.github.io/FRoM-W1)**\n", "2601.12790": "- 2026-01-19, **FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation**, Yue Gao Team, Paper: [http://arxiv.org/abs/2601.12790](http://arxiv.org/abs/2601.12790)\n", "2601.11328": "- 2026-01-20, **ProjecTA: A Semi-Humanoid Robotic Teaching Assistant with In-Situ Projection for Guided Tours**, Pengcheng An Team, Paper: [http://arxiv.org/abs/2601.11328](http://arxiv.org/abs/2601.11328)\n", "2601.10365": "- 2026-01-15, **FastStair: Learning to Run Up Stairs with Humanoid Robots**, Jie Zhao Team, Paper: [http://arxiv.org/abs/2601.10365](http://arxiv.org/abs/2601.10365)\n", "2601.09518": "- 2026-01-14, **Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations**, Wei-Shi Zheng Team, Paper: [http://arxiv.org/abs/2601.09518](http://arxiv.org/abs/2601.09518)\n", "2601.09031": "- 2026-01-13, **Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation**, Miao Li Team, Paper: [http://arxiv.org/abs/2601.09031](http://arxiv.org/abs/2601.09031)\n", "2601.09755": "- 2026-01-13, **Heterogeneous computing platform for real-time robotics**, Steve Furber Team, Paper: [http://arxiv.org/abs/2601.09755](http://arxiv.org/abs/2601.09755)\n", "2601.07454": "- 2026-01-12, **WaveMan: mmWave-Based Room-Scale Human Interaction Perception for Humanoid Robots**, Jianfei Yang Team, Paper: [http://arxiv.org/abs/2601.07454](http://arxiv.org/abs/2601.07454)\n", "2601.07284": "- 2026-01-12, **AdaMorph: Unified Motion Retargeting via Embodiment-Aware Adaptive Transformers**, Zecui Zeng Team, Paper: [http://arxiv.org/abs/2601.07284](http://arxiv.org/abs/2601.07284)\n", "2601.07052": "- 2026-01-11, **RSLCPP -- Deterministic Simulations Using ROS 2**, Markus Lienkamp Team, Paper: [http://arxiv.org/abs/2601.07052](http://arxiv.org/abs/2601.07052)\n", "2602.02481": "- 2026-02-02, **Flow Policy Gradients for Robot Control**, Angjoo Kanazawa Team, Paper: [http://arxiv.org/abs/2602.02481](http://arxiv.org/abs/2602.02481), Code: **[https://hongsukchoi.github.io/fpo-control](https://hongsukchoi.github.io/fpo-control)**\n", "2602.02473": "- 2026-02-02, **HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos**, Ping Tan Team, Paper: [http://arxiv.org/abs/2602.02473](http://arxiv.org/abs/2602.02473)\n", "2602.02331": "- 2026-02-02, **TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour**, Hang Zhao Team, Paper: [http://arxiv.org/abs/2602.02331](http://arxiv.org/abs/2602.02331), Code: **[https://ttt-parkour.github.io/](https://ttt-parkour.github.io/)**\n", "2602.01632": "- 2026-02-02, **A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation**, Shreyas Kousik Team, Paper: [http://arxiv.org/abs/2602.01632](http://arxiv.org/abs/2602.01632), Code: **[https://sew-mimic.com/](https://sew-mimic.com/)**\n", "2602.01515": "- 2026-02-02, **RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots**, David Howard Team, Paper: [http://arxiv.org/abs/2602.01515](http://arxiv.org/abs/2602.01515)\n", "2602.01352": "- 2026-02-01, **T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation**, Xiaochun Mai Team, Paper: [http://arxiv.org/abs/2602.01352](http://arxiv.org/abs/2602.01352)\n", "2602.00919": "- 2026-01-31, **Green-VLA: Staged Vision-Language-Action Model for Generalist Robots**, A. Postnikov Team, Paper: [http://arxiv.org/abs/2602.00919](http://arxiv.org/abs/2602.00919)\n", "2602.00401": "- 2026-01-30, **ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control**, Farbod Farshidian Team, Paper: [http://arxiv.org/abs/2602.00401](http://arxiv.org/abs/2602.00401)\n", "2602.04851": "- 2026-02-04, **PDF-HR: Pose Distance Fields for Humanoid Robots**, Renjing Xu Team, Paper: [http://arxiv.org/abs/2602.04851](http://arxiv.org/abs/2602.04851), Code: **[https://gaoyukang33.github.io/PDF-HR/}{Project](https://gaoyukang33.github.io/PDF-HR/}{Project)**\n", "2602.04515": "- 2026-02-04, **EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models**, B\u00f6rje F. Karlsson Team, Paper: [http://arxiv.org/abs/2602.04515](http://arxiv.org/abs/2602.04515)\n", "2602.04412": "- 2026-02-05, **HoRD: Robust Humanoid Control via History-Conditioned Reinforcement Learning and Online Distillation**, Hong Jia Team, Paper: [http://arxiv.org/abs/2602.04412](http://arxiv.org/abs/2602.04412)\n", "2602.05855": "- 2026-02-05, **A Hybrid Autoencoder for Robust Heightmap Generation from Fused Lidar and Depth Data for Humanoid Robot Locomotion**, Simon F. G. Ehlers Team, Paper: [http://arxiv.org/abs/2602.05855](http://arxiv.org/abs/2602.05855)\n", "2602.05791": "- 2026-02-05, **Scalable and General Whole-Body Control for Cross-Humanoid Locomotion**, Weinan Zhang Team, Paper: [http://arxiv.org/abs/2602.05791](http://arxiv.org/abs/2602.05791)\n", "2602.05596": "- 2026-02-05, **TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards**, Jaeheung Park Team, Paper: [http://arxiv.org/abs/2602.05596](http://arxiv.org/abs/2602.05596)\n", "2602.05310": "- 2026-02-05, **Learning Soccer Skills for Humanoid Robots: A Progressive Perception-Action Framework**, Xuelong Li Team, Paper: [http://arxiv.org/abs/2602.05310](http://arxiv.org/abs/2602.05310)\n", "2602.06445": "- 2026-02-06, **ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking**, Yao Su Team, Paper: [http://arxiv.org/abs/2602.06445](http://arxiv.org/abs/2602.06445)\n"}, "Humanoid-Locomotion": {"2601.21363": "- 2026-01-29, **Towards Bridging the Gap between Large-Scale Pretraining and Efficient Finetuning for Humanoid Control**, Jingwen Zhang Team, Paper: [http://arxiv.org/abs/2601.21363](http://arxiv.org/abs/2601.21363)\n", "2601.20668": "- 2026-01-28, **GPO: Growing Policy Optimization for Legged Robot Locomotion and Whole-Body Control**, Guillaume Sartoretti Team, Paper: [http://arxiv.org/abs/2601.20668](http://arxiv.org/abs/2601.20668)\n", "2601.16109": "- 2026-01-22, **Efficiently Learning Robust Torque-based Locomotion Through Reinforcement with Model-Based Supervision**, Dongheui Lee Team, Paper: [http://arxiv.org/abs/2601.16109](http://arxiv.org/abs/2601.16109)\n", "2601.08485": "- 2026-01-13, **AME-2: Agile and Generalized Legged Locomotion via Attention-Based Neural Map Encoding**, Marco Hutter Team, Paper: [http://arxiv.org/abs/2601.08485](http://arxiv.org/abs/2601.08485)\n", "2601.06286": "- 2026-01-09, **Walk the PLANC: Physics-Guided RL for Agile Humanoid Locomotion on Constrained Footholds**, Aaron D. Ames Team, Paper: [http://arxiv.org/abs/2601.06286](http://arxiv.org/abs/2601.06286)\n", "2601.03607": "- 2026-01-07, **Locomotion Beyond Feet**, C. Karen Liu Team, Paper: [http://arxiv.org/abs/2601.03607](http://arxiv.org/abs/2601.03607), Code: **[https://locomotion-beyond-feet.github.io/](https://locomotion-beyond-feet.github.io/)**\n", "2512.24698": "- 2025-12-31, **Dynamic Policy Learning for Legged Robot with Simplified Model Pretraining and Model Homotopy Transfer**, Hae-Won Park Team, Paper: [http://arxiv.org/abs/2512.24698](http://arxiv.org/abs/2512.24698)\n", "2512.23650": "- 2026-01-04, **Do You Have Freestyle? Expressive Humanoid Locomotion via Audio Control**, Shanghang Zhang Team, Paper: [http://arxiv.org/abs/2512.23650](http://arxiv.org/abs/2512.23650)\n", "2512.23649": "- 2026-01-04, **RoboMirror: Understand Before You Imitate for Video to Humanoid Locomotion**, Shanghang Zhang Team, Paper: [http://arxiv.org/abs/2512.23649](http://arxiv.org/abs/2512.23649)\n", "2512.20322": "- 2025-12-23, **Pneumatic bladder links with wide range of motion joints for articulated inflatable robots**, Ryuma Niiyama Team, Paper: [http://arxiv.org/abs/2512.20322](http://arxiv.org/abs/2512.20322)\n", "2512.16446": "- 2025-12-18, **E-SDS: Environment-aware See it, Do it, Sorted - Automated Environment-Aware Reinforcement Learning for Humanoid Locomotion**, Dimitrios Kanoulas Team, Paper: [http://arxiv.org/abs/2512.16446](http://arxiv.org/abs/2512.16446)\n", "2512.12993": "- 2025-12-15, **Learning Terrain Aware Bipedal Locomotion via Reduced Dimensional Perceptual Representations**, Ayonga Hereid Team, Paper: [http://arxiv.org/abs/2512.12993](http://arxiv.org/abs/2512.12993)\n", "2512.07464": "- 2025-12-08, **Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction**, Houqiang Li Team, Paper: [http://arxiv.org/abs/2512.07464](http://arxiv.org/abs/2512.07464)\n", "2512.03459": "- 2025-12-03, **Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion**, Jun Morimoto Team, Paper: [http://arxiv.org/abs/2512.03459](http://arxiv.org/abs/2512.03459)\n", "2512.01996": "- 2025-12-01, **Learning Sim-to-Real Humanoid Locomotion in 15 Minutes**, Pieter Abbeel Team, Paper: [http://arxiv.org/abs/2512.01996](http://arxiv.org/abs/2512.01996), Code: **[https://younggyo.me/fastsac-humanoid](https://younggyo.me/fastsac-humanoid)**\n", "2512.00971": "- 2025-11-30, **H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer**, Weinan Zhang Team, Paper: [http://arxiv.org/abs/2512.00971](http://arxiv.org/abs/2512.00971)\n", "2511.22963": "- 2025-11-28, **Commanding Humanoid by Free-form Language: A Large Language Action Model with Unified Motion Vocabulary**, Jingya Wang Team, Paper: [http://arxiv.org/abs/2511.22963](http://arxiv.org/abs/2511.22963), Code: **[https://humanoidlla.github.io/](https://humanoidlla.github.io/)**\n", "2511.22744": "- 2025-11-27, **Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion**, Wael Suleiman Team, Paper: [http://arxiv.org/abs/2511.22744](http://arxiv.org/abs/2511.22744), Code: **[https://anonymous.4open.science/r/multiview-parkour-6FB8](https://anonymous.4open.science/r/multiview-parkour-6FB8)**\n", "2511.20275": "- 2026-01-29, **HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments**, Bin He Team, Paper: [http://arxiv.org/abs/2511.20275](http://arxiv.org/abs/2511.20275)\n", "2512.00077": "- 2025-11-25, **A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs**, Bowen Zhi Team, Paper: [http://arxiv.org/abs/2512.00077](http://arxiv.org/abs/2512.00077)\n", "2602.02481": "- 2026-02-02, **Flow Policy Gradients for Robot Control**, Angjoo Kanazawa Team, Paper: [http://arxiv.org/abs/2602.02481](http://arxiv.org/abs/2602.02481), Code: **[https://hongsukchoi.github.io/fpo-control](https://hongsukchoi.github.io/fpo-control)**\n", "2602.03511": "- 2026-02-03, **CMR: Contractive Mapping Embeddings for Robust Humanoid Locomotion on Unstructured Terrains**, Chao Huang Team, Paper: [http://arxiv.org/abs/2602.03511](http://arxiv.org/abs/2602.03511)\n", "2602.03397": "- 2026-02-03, **Enhancing Navigation Efficiency of Quadruped Robots via Leveraging Personal Transportation Platforms**, Sung-Eui Yoon Team, Paper: [http://arxiv.org/abs/2602.03397](http://arxiv.org/abs/2602.03397), Code: **[https://sgvr.kaist.ac.kr/~msyoon/papers/ICRA25/\"](https://sgvr.kaist.ac.kr/~msyoon/papers/ICRA25/\")**\n", "2602.05791": "- 2026-02-05, **Scalable and General Whole-Body Control for Cross-Humanoid Locomotion**, Weinan Zhang Team, Paper: [http://arxiv.org/abs/2602.05791](http://arxiv.org/abs/2602.05791)\n", "2602.05596": "- 2026-02-05, **TOLEBI: Learning Fault-Tolerant Bipedal Locomotion via Online Status Estimation and Fallibility Rewards**, Jaeheung Park Team, Paper: [http://arxiv.org/abs/2602.05596](http://arxiv.org/abs/2602.05596)\n", "2602.06445": "- 2026-02-06, **ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking**, Yao Su Team, Paper: [http://arxiv.org/abs/2602.06445](http://arxiv.org/abs/2602.06445)\n", "2602.06382": "- 2026-02-06, **Now You See That: Learning End-to-End Humanoid Locomotion from Raw Pixels**, Zongwu Xie Team, Paper: [http://arxiv.org/abs/2602.06382](http://arxiv.org/abs/2602.06382)\n", "2602.06341": "- 2026-02-06, **HiWET: Hierarchical World-Frame End-Effector Tracking for Long-Horizon Humanoid Loco-Manipulation**, Yue Gao Team, Paper: [http://arxiv.org/abs/2602.06341](http://arxiv.org/abs/2602.06341)\n"}, "VLN-Navigation": {"2601.21751": "- 2026-01-29, **Dynamic Topology Awareness: Breaking the Granularity Rigidity in Vision-Language Navigation**, Xiaoming Wang Team, Paper: [http://arxiv.org/abs/2601.21751](http://arxiv.org/abs/2601.21751)\n", "2601.18188": "- 2026-01-26, **\\textsc{NaVIDA}: Vision-Language Navigation with Inverse Dynamics Augmentation**, Feng Zheng Team, Paper: [http://arxiv.org/abs/2601.18188](http://arxiv.org/abs/2601.18188)\n", "2601.13976": "- 2026-01-23, **FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation**, Yonggang Qi Team, Paper: [http://arxiv.org/abs/2601.13976](http://arxiv.org/abs/2601.13976)\n", "2601.09111": "- 2026-01-14, **Towards Open Environments and Instructions: General Vision-Language Navigation via Fast-Slow Interactive Reasoning**, Yahong Han Team, Paper: [http://arxiv.org/abs/2601.09111](http://arxiv.org/abs/2601.09111)\n", "2601.08665": "- 2026-01-13, **VLingNav: Embodied Navigation with Adaptive Reasoning and Visual-Assisted Linguistic Memory**, Junzhi Yu Team, Paper: [http://arxiv.org/abs/2601.08665](http://arxiv.org/abs/2601.08665), Code: **[https://wsakobe.github.io/VLingNav-web/](https://wsakobe.github.io/VLingNav-web/)**\n", "2601.08868": "- 2026-01-11, **Residual Cross-Modal Fusion Networks for Audio-Visual Navigation**, Bin Ren Team, Paper: [http://arxiv.org/abs/2601.08868](http://arxiv.org/abs/2601.08868)\n", "2601.03707": "- 2026-01-07, **AirNav: A Large-Scale Real-World UAV Vision-and-Language Navigation Dataset with Natural and Diverse Instructions**, Renxin Zhong Team, Paper: [http://arxiv.org/abs/2601.03707](http://arxiv.org/abs/2601.03707)\n", "2601.02167": "- 2026-01-19, **LocoScooter: Designing a Stationary Scooter-Based Locomotion System for Navigation in Virtual Reality**, Ge Lin Kan Team, Paper: [http://arxiv.org/abs/2601.02167](http://arxiv.org/abs/2601.02167)\n", "2601.01872": "- 2026-01-05, **CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios**, Xueqian Wang Team, Paper: [http://arxiv.org/abs/2601.01872](http://arxiv.org/abs/2601.01872)\n", "2512.24851": "- 2026-01-06, **VLN-MME: Diagnosing MLLMs as Language-guided Visual Navigation agents**, Qi Wu Team, Paper: [http://arxiv.org/abs/2512.24851](http://arxiv.org/abs/2512.24851)\n", "2512.22342": "- 2026-01-23, **VL-LN Bench: Towards Long-horizon Goal-oriented Navigation with Active Dialogs**, Jiangmiao Pang Team, Paper: [http://arxiv.org/abs/2512.22342](http://arxiv.org/abs/2512.22342)\n", "2512.21714": "- 2025-12-25, **AstraNav-World: World Model for Foresight Control and Consistency**, Shanghang Zhang Team, Paper: [http://arxiv.org/abs/2512.21714](http://arxiv.org/abs/2512.21714)\n", "2512.21627": "- 2025-12-25, **AstraNav-Memory: Contexts Compression for Long Memory**, Mu Xu Team, Paper: [http://arxiv.org/abs/2512.21627](http://arxiv.org/abs/2512.21627)\n", "2512.20940": "- 2025-12-24, **ETP-R1: Evolving Topological Planning with Reinforcement Fine-tuning for Vision-Language Navigation in Continuous Environments**, Yue Wang Team, Paper: [http://arxiv.org/abs/2512.20940](http://arxiv.org/abs/2512.20940)\n", "2512.20206": "- 2025-12-23, **TongSIM: A General Platform for Simulating Intelligent Machines**, Zhenliang Zhang Team, Paper: [http://arxiv.org/abs/2512.20206](http://arxiv.org/abs/2512.20206)\n", "2512.19024": "- 2025-12-22, **IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments**, Zhouhui Lian Team, Paper: [http://arxiv.org/abs/2512.19024](http://arxiv.org/abs/2512.19024)\n", "2512.19021": "- 2025-12-22, **VLNVerse: A Benchmark for Vision-Language Navigation with Versatile, Embodied, Realistic Simulation and Evaluation**, Qi Wu Team, Paper: [http://arxiv.org/abs/2512.19021](http://arxiv.org/abs/2512.19021)\n", "2512.18028": "- 2025-12-19, **Embodied4C: Measuring What Matters for Embodied Vision-Language Navigation**, Eric Sax Team, Paper: [http://arxiv.org/abs/2512.18028](http://arxiv.org/abs/2512.18028)\n", "2512.17435": "- 2026-01-08, **ImagineNav++: Prompting Vision-Language Models as Embodied Navigator through Scene Imagination**, Changyin Sun Team, Paper: [http://arxiv.org/abs/2512.17435](http://arxiv.org/abs/2512.17435)\n", "2512.15047": "- 2025-12-17, **HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles**, Renjing Xu Team, Paper: [http://arxiv.org/abs/2512.15047](http://arxiv.org/abs/2512.15047)\n", "2602.02220": "- 2026-02-02, **LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation**, Anton van den Hengel Team, Paper: [http://arxiv.org/abs/2602.02220](http://arxiv.org/abs/2602.02220)\n", "2602.00222": "- 2026-02-03, **MapDream: Task-Driven Map Learning for Vision-Language Navigation**, Zhaoxin Fan Team, Paper: [http://arxiv.org/abs/2602.00222](http://arxiv.org/abs/2602.00222)\n", "2602.05827": "- 2026-02-05, **Sparse Video Generation Propels Real-World Beyond-the-View Vision-Language Navigation**, Hongyang Li Team, Paper: [http://arxiv.org/abs/2602.05827](http://arxiv.org/abs/2602.05827)\n", "2602.05789": "- 2026-02-05, **Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation**, Weiming Zhang Team, Paper: [http://arxiv.org/abs/2602.05789](http://arxiv.org/abs/2602.05789)\n", "2602.06427": "- 2026-02-06, **Bridging the Indoor-Outdoor Gap: Vision-Centric Instruction-Guided Embodied Navigation for the Last Meters**, Mu Xu Team, Paper: [http://arxiv.org/abs/2602.06427](http://arxiv.org/abs/2602.06427)\n", "2602.06356": "- 2026-02-06, **Nipping the Drift in the Bud: Retrospective Rectification for Robust Vision-Language Navigation**, Weiying Xie Team, Paper: [http://arxiv.org/abs/2602.06356](http://arxiv.org/abs/2602.06356)\n"}, "VLA-Navigation": {"2508.10416": "- 2025-08-14, **CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model**, Hao Dong Team, Paper: [http://arxiv.org/abs/2508.10416](http://arxiv.org/abs/2508.10416)\n", "2407.07775": "- 2024-07-12, **Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs**, Jie Tan Team, Paper: [http://arxiv.org/abs/2407.07775](http://arxiv.org/abs/2407.07775)\n"}, "Dexterous": {"2601.21474": "- 2026-01-29, **DexTac: Learning Contact-aware Visuotactile Policies via Hand-by-hand Teaching**, Shuo Wang Team, Paper: [http://arxiv.org/abs/2601.21474](http://arxiv.org/abs/2601.21474)\n", "2601.18121": "- 2026-01-26, **Grasp-and-Lift: Executable 3D Hand-Object Interaction Reconstruction via Physics-in-the-Loop Optimization**, Jongwoo Lim Team, Paper: [http://arxiv.org/abs/2601.18121](http://arxiv.org/abs/2601.18121)\n", "2601.17440": "- 2026-01-24, **PILOT: A Perceptive Integrated Low-level Controller for Loco-manipulation over Unstructured Scenes**, Hesheng Wang Team, Paper: [http://arxiv.org/abs/2601.17440](http://arxiv.org/abs/2601.17440)\n", "2601.15039": "- 2026-01-31, **CADGrasp: Learning Contact and Collision Aware General Dexterous Grasping in Cluttered Scenes**, Hao Dong Team, Paper: [http://arxiv.org/abs/2601.15039](http://arxiv.org/abs/2601.15039)\n", "2601.10930": "- 2026-01-23, **Where to Touch, How to Contact: Hierarchical RL-MPC Framework for Geometry-Aware Long-Horizon Dexterous Manipulation**, Wanxin Jin Team, Paper: [http://arxiv.org/abs/2601.10930](http://arxiv.org/abs/2601.10930)\n", "2601.08246": "- 2026-01-13, **FSAG: Enhancing Human-to-Dexterous-Hand Finger-Specific Affordance Grounding via Diffusion Models**, Wenzhao Lian Team, Paper: [http://arxiv.org/abs/2601.08246](http://arxiv.org/abs/2601.08246)\n", "2601.07559": "- 2026-01-12, **Stable In-hand Manipulation for a Lightweight Four-motor Prosthetic Hand**, Masashi Hamaya Team, Paper: [http://arxiv.org/abs/2601.07559](http://arxiv.org/abs/2601.07559)\n", "2601.05844": "- 2026-01-09, **DexterCap: An Affordable and Automated System for Capturing Dexterous Hand-Object Manipulation**, Libin Liu Team, Paper: [http://arxiv.org/abs/2601.05844](http://arxiv.org/abs/2601.05844)\n", "2601.04629": "- 2026-01-08, **UniBiDex: A Unified Teleoperation Framework for Robotic Bimanual Dexterous Manipulation**, Peng Zhou Team, Paper: [http://arxiv.org/abs/2601.04629](http://arxiv.org/abs/2601.04629)\n", "2601.02778": "- 2026-01-09, **Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation**, Zhibin Li Team, Paper: [http://arxiv.org/abs/2601.02778](http://arxiv.org/abs/2601.02778)\n", "2601.01651": "- 2026-01-04, **DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos**, Robert B. Fisher Team, Paper: [http://arxiv.org/abs/2601.01651](http://arxiv.org/abs/2601.01651)\n", "2512.24965": "- 2025-12-31, **ShowUI-$\u03c0$: Flow-based Generative Models as GUI Dexterous Hands**, Mike Zheng Shou Team, Paper: [http://arxiv.org/abs/2512.24965](http://arxiv.org/abs/2512.24965)\n", "2512.24657": "- 2025-12-31, **Antagonistic Bowden-Cable Actuation of a Lightweight Robotic Hand: Toward Dexterous Manipulation for Payload Constrained Humanoids**, David Hyunchul Shim Team, Paper: [http://arxiv.org/abs/2512.24657](http://arxiv.org/abs/2512.24657)\n", "2512.24310": "- 2026-01-01, **World In Your Hands: A Large-Scale and Open-source Ecosystem for Learning Human-centric Manipulation in the Wild**, Wenchao Ding Team, Paper: [http://arxiv.org/abs/2512.24310](http://arxiv.org/abs/2512.24310)\n", "2512.24210": "- 2026-01-09, **GR-Dexter Technical Report**, Hang Li Team, Paper: [http://arxiv.org/abs/2512.24210](http://arxiv.org/abs/2512.24210)\n", "2512.21233": "- 2025-12-29, **UniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer**, Zongqing Lu Team, Paper: [http://arxiv.org/abs/2512.21233](http://arxiv.org/abs/2512.21233)\n", "2512.19583": "- 2025-12-22, **Learning Generalizable Hand-Object Tracking from Synthetic Demonstrations**, Ping Tan Team, Paper: [http://arxiv.org/abs/2512.19583](http://arxiv.org/abs/2512.19583)\n", "2512.18068": "- 2025-12-19, **SurgiPose: Estimating Surgical Tool Kinematics from Monocular Video for Surgical Robot Learning**, Axel Krieger Team, Paper: [http://arxiv.org/abs/2512.18068](http://arxiv.org/abs/2512.18068)\n", "2512.15020": "- 2025-12-17, **ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision**, Jie Mei Team, Paper: [http://arxiv.org/abs/2512.15020](http://arxiv.org/abs/2512.15020)\n", "2512.13644": "- 2025-12-15, **World Models Can Leverage Human Videos for Dexterous Manipulation**, Yann LeCun Team, Paper: [http://arxiv.org/abs/2512.13644](http://arxiv.org/abs/2512.13644)\n", "2602.02142": "- 2026-02-02, **FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation**, Haiyue Zhu Team, Paper: [http://arxiv.org/abs/2602.02142](http://arxiv.org/abs/2602.02142)\n", "2602.01789": "- 2026-02-05, **RFS: Reinforcement Learning with Residual Flow Steering for Dexterous Manipulation**, Abhishek Gupta Team, Paper: [http://arxiv.org/abs/2602.01789](http://arxiv.org/abs/2602.01789)\n", "2602.01067": "- 2026-02-01, **A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation**, Jose Barreiros Team, Paper: [http://arxiv.org/abs/2602.01067](http://arxiv.org/abs/2602.01067)\n", "2601.05248": "- 2026-02-02, **LaST$_{0}$: Latent Spatio-Temporal Chain-of-Thought for Robotic Vision-Language-Action Model**, Shanghang Zhang Team, Paper: [http://arxiv.org/abs/2601.05248](http://arxiv.org/abs/2601.05248)\n", "2602.03445": "- 2026-02-03, **CRL-VLA: Continual Vision-Language-Action Learning**, Chao Huang Team, Paper: [http://arxiv.org/abs/2602.03445](http://arxiv.org/abs/2602.03445)\n", "2602.04672": "- 2026-02-04, **AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation**, Chunhua Shen Team, Paper: [http://arxiv.org/abs/2602.04672](http://arxiv.org/abs/2602.04672)\n", "2602.05513": "- 2026-02-05, **DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter**, Zhenguo Sun Team, Paper: [http://arxiv.org/abs/2602.05513](http://arxiv.org/abs/2602.05513)\n", "2602.05468": "- 2026-02-05, **TaSA: Two-Phased Deep Predictive Learning of Tactile Sensory Attenuation for Improving In-Grasp Manipulation**, Shigeki Sugano Team, Paper: [http://arxiv.org/abs/2602.05468](http://arxiv.org/abs/2602.05468)\n", "2602.05325": "- 2026-02-05, **RoboPaint: From Human Demonstration to Any Robot and Any View**, Zhengxue Cheng Team, Paper: [http://arxiv.org/abs/2602.05325](http://arxiv.org/abs/2602.05325)\n", "2602.05233": "- 2026-02-05, **MobileManiBench: Simplifying Model Verification for Mobile Manipulation**, Baining Guo Team, Paper: [http://arxiv.org/abs/2602.05233](http://arxiv.org/abs/2602.05233)\n"}, "Semantic-SLAM": {"2601.05738": "- 2026-01-09, **FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time**, Simon Hadfield Team, Paper: [http://arxiv.org/abs/2601.05738](http://arxiv.org/abs/2601.05738)\n", "2512.01889": "- 2025-12-01, **KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM**, Sergey Kolyubin Team, Paper: [http://arxiv.org/abs/2512.01889](http://arxiv.org/abs/2512.01889)\n", "2511.22968": "- 2025-11-28, **Taming the Light: Illumination-Invariant Semantic 3DGS-SLAM**, Zhenhong Jia Team, Paper: [http://arxiv.org/abs/2511.22968](http://arxiv.org/abs/2511.22968)\n", "2511.16282": "- 2025-11-27, **Building temporally coherent 3D maps with VGGT for memory-efficient Semantic SLAM**, Anna Gelencs\u00e9r-Horv\u00e1th Team, Paper: [http://arxiv.org/abs/2511.16282](http://arxiv.org/abs/2511.16282)\n", "2510.00783": "- 2025-10-01, **Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions**, Nak Young Chong Team, Paper: [http://arxiv.org/abs/2510.00783](http://arxiv.org/abs/2510.00783)\n", "2509.14949": "- 2025-09-18, **Human Interaction for Collaborative Semantic SLAM using Extended Reality**, Jose Luis Sanchez-Lopez Team, Paper: [http://arxiv.org/abs/2509.14949](http://arxiv.org/abs/2509.14949)\n", "2507.12093": "- 2025-07-16, **Tree-SLAM: semantic object SLAM for efficient mapping of individual trees in orchards**, Gert Kootstra Team, Paper: [http://arxiv.org/abs/2507.12093](http://arxiv.org/abs/2507.12093)\n", "2506.06517": "- 2025-12-03, **GS4: Generalizable Sparse Splatting Semantic SLAM**, Li Fuxin Team, Paper: [http://arxiv.org/abs/2506.06517](http://arxiv.org/abs/2506.06517)\n", "2506.02736": "- 2025-06-03, **GeneA-SLAM2: Dynamic SLAM with AutoEncoder-Preprocessed Genetic Keypoints Resampling and Depth Variance-Guided Dynamic Region Removal**, Yingchun Fan Team, Paper: [http://arxiv.org/abs/2506.02736](http://arxiv.org/abs/2506.02736)\n", "2505.12384": "- 2025-05-18, **Is Semantic SLAM Ready for Embedded Systems ? A Comparative Survey**, Fran\u00e7ois Goulette Team, Paper: [http://arxiv.org/abs/2505.12384](http://arxiv.org/abs/2505.12384)\n", "2504.19409": "- 2025-05-16, **GSFF-SLAM: 3D Semantic Gaussian Splatting SLAM via Feature Field**, Changyin Sun Team, Paper: [http://arxiv.org/abs/2504.19409](http://arxiv.org/abs/2504.19409)\n", "2504.01997": "- 2025-04-01, **Semantic SLAM with Rolling-Shutter Cameras and Low-Precision INS in Outdoor Environments**, Haoyi Xiong Team, Paper: [http://arxiv.org/abs/2504.01997](http://arxiv.org/abs/2504.01997)\n", "2503.01646": "- 2025-03-03, **OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding**, Mengyin Fu Team, Paper: [http://arxiv.org/abs/2503.01646](http://arxiv.org/abs/2503.01646)\n", "2502.14931": "- 2025-07-09, **Hier-SLAM++: Neuro-Symbolic Semantic SLAM with a Hierarchically Categorical Gaussian Splatting**, Hamid Rezatofighi Team, Paper: [http://arxiv.org/abs/2502.14931](http://arxiv.org/abs/2502.14931)\n", "2501.00352": "- 2024-12-31, **PanoSLAM: Panoptic 3D Scene Reconstruction via Gaussian SLAM**, Tongliang Liu Team, Paper: [http://arxiv.org/abs/2501.00352](http://arxiv.org/abs/2501.00352)\n", "2410.12169": "- 2025-07-11, **Towards Autonomous Indoor Parking: A Globally Consistent Semantic SLAM System and A Semantic Localization Subsystem**, Hesheng Wang Team, Paper: [http://arxiv.org/abs/2410.12169](http://arxiv.org/abs/2410.12169)\n", "2409.12518": "- 2025-03-10, **Hier-SLAM: Scaling-up Semantics in SLAM with a Hierarchically Categorical Gaussian Splatting**, Hamid Rezatofighi Team, Paper: [http://arxiv.org/abs/2409.12518](http://arxiv.org/abs/2409.12518), Code: **[https://github.com/LeeBY68/Hier-SLAM](https://github.com/LeeBY68/Hier-SLAM)**\n", "2408.14726": "- 2024-09-02, **Active Semantic Mapping and Pose Graph Spectral Analysis for Robot Exploration**, Giovanni Beltrame Team, Paper: [http://arxiv.org/abs/2408.14726](http://arxiv.org/abs/2408.14726)\n", "2406.17249": "- 2025-10-03, **SlideSLAM: Sparse, Lightweight, Decentralized Metric-Semantic SLAM for Multi-Robot Navigation**, Vijay Kumar Team, Paper: [http://arxiv.org/abs/2406.17249](http://arxiv.org/abs/2406.17249)\n", "2406.05849": "- 2024-06-09, **MAP-ADAPT: Real-Time Quality-Adaptive Semantic 3D Maps**, Iro Armeni Team, Paper: [http://arxiv.org/abs/2406.05849](http://arxiv.org/abs/2406.05849)\n"}}